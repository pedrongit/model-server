{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import make_tensor_proto, make_ndarray\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "# Define ImageNet class labels (simplified example)\n",
    "imagenet_classes = {\n",
    "    0: \"tench\",\n",
    "    1: \"goldfish\",\n",
    "    340: \"zebra\",\n",
    "    644: \"match\",\n",
    "    # Add more labels as needed...\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess_image(image_path, size=224):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    img = img.transpose(2, 0, 1)  # HWC to CHW\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "\n",
    "# Run inference and process the output\n",
    "def infer_image(image_path, grpc_address, grpc_port, model_name, input_name, output_name):\n",
    "    # Create gRPC channel and stub\n",
    "    channel = grpc.insecure_channel(f\"{grpc_address}:{grpc_port}\")\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_data = preprocess_image(image_path)\n",
    "    print(f\"Input shape: {input_data.shape}, dtype: {input_data.dtype}, range: {np.min(input_data)}-{np.max(input_data)}\")\n",
    "\n",
    "    # Create gRPC PredictRequest\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = model_name\n",
    "    request.inputs[input_name].CopyFrom(make_tensor_proto(input_data, shape=input_data.shape))\n",
    "\n",
    "    # Send request and get response\n",
    "    response = stub.Predict(request, timeout=10.0)\n",
    "\n",
    "    # Extract the tensor content\n",
    "    output = make_ndarray(response.outputs[output_name])\n",
    "    predicted_class = np.argmax(output)\n",
    "\n",
    "    # Map class index to label\n",
    "    label = imagenet_classes.get(predicted_class, \"Unknown\")\n",
    "    return predicted_class, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 3, 224, 224), dtype: float32, range: 0.0-1.0\n",
      "Error during inference: Cannot convert the argument `type_value`: 0 to a TensorFlow DType.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    grpc_address = \"pecosv\"\n",
    "    grpc_port = 9000\n",
    "    model_name = \"resnet\"\n",
    "    input_name = \"0\"  # Input tensor name from logs\n",
    "    output_name = \"prob\"  # Confirm with model metadata\n",
    "    image_path = \"C:/Users/pedro/Documents/developer/model-server/assets/zebra.jpeg\"\n",
    "\n",
    "    try:\n",
    "        # Run inference\n",
    "        predicted_class, label = infer_image(image_path, grpc_address, grpc_port, model_name, input_name, output_name)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Predicted Class Index: {predicted_class}\")\n",
    "        print(f\"Predicted Label: {label}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: float32, shape: (1, 3, 224, 224), range: 0.0 - 1.0\n",
      "Error during inference: Cannot convert the argument `type_value`: 0 to a TensorFlow DType.\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import make_tensor_proto, make_ndarray\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "# Define ImageNet class labels (simplified, replace with full mapping)\n",
    "imagenet_classes = {\n",
    "    0: \"tench\",\n",
    "    1: \"goldfish\",\n",
    "    2: \"great white shark\",\n",
    "    340: \"zebra\",  # Include relevant classes for simplicity\n",
    "    # Add more classes as needed...\n",
    "}\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(image_path, size=224):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    img = img.transpose(2, 0, 1)  # HWC to CHW\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Run inference and process the output\n",
    "def infer_image(image_path, grpc_address, grpc_port, model_name, input_name, output_name):\n",
    "    # Create gRPC channel and stub\n",
    "    channel = grpc.insecure_channel(f\"{grpc_address}:{grpc_port}\")\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_data = preprocess_image(image_path)\n",
    "\n",
    "    # Create gRPC PredictRequest\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = model_name\n",
    "    request.inputs[input_name].CopyFrom(\n",
    "    make_tensor_proto(input_data, dtype=np.float32, shape=input_data.shape)\n",
    ")\n",
    "\n",
    "\n",
    "    # Send request and get response\n",
    "    response = stub.Predict(request, timeout=10.0)\n",
    "    print(f\"Input data type: {input_data.dtype}, shape: {input_data.shape}, range: {input_data.min()} - {input_data.max()}\")\n",
    "\n",
    "    # Extract the tensor content\n",
    "    output = make_ndarray(response.outputs[output_name])\n",
    "    predicted_class = np.argmax(output)\n",
    "\n",
    "    # Map class index to label\n",
    "    label = imagenet_classes.get(predicted_class, \"Unknown\")\n",
    "    return predicted_class, label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    grpc_address = \"pecosv\"\n",
    "    grpc_port = 9000\n",
    "    model_name = \"resnet\"\n",
    "    input_name = \"0\"\n",
    "    output_name = \"1463\"\n",
    "\n",
    "    image_path = \"C:/Users/pedro/Documents/developer/model-server/assets/zebra.jpeg\"\n",
    "\n",
    "    try:\n",
    "        # Run inference\n",
    "        predicted_class, label = infer_image(image_path, grpc_address, grpc_port, model_name, input_name, output_name)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Predicted Class Index: {predicted_class}\")\n",
    "        print(f\"Predicted Label: {label}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelSpec': {'name': 'resnet', 'signatureName': '', 'version': '1'}, 'metadata': {'signature_def': {'@type': 'type.googleapis.com/tensorflow.serving.SignatureDefMap', 'signatureDef': {'serving_default': {'inputs': {'0': {'dtype': 'DT_FLOAT', 'tensorShape': {'dim': [{'size': '1', 'name': ''}, {'size': '3', 'name': ''}, {'size': '224', 'name': ''}, {'size': '224', 'name': ''}], 'unknownRank': False}, 'name': '0'}}, 'outputs': {'1463': {'dtype': 'DT_FLOAT', 'tensorShape': {'dim': [{'size': '1', 'name': ''}, {'size': '1000', 'name': ''}], 'unknownRank': False}, 'name': '1463'}}, 'methodName': '', 'defaults': {}}}}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://pecosv:9001/v1/models/resnet/metadata\"\n",
    "response = requests.get(url)\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
